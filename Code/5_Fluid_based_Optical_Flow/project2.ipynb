{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T04:23:23.086011Z",
     "start_time": "2020-02-17T04:23:20.086578Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets as datasets\n",
    "from torchvision import transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T05:58:55.073762Z",
     "start_time": "2020-02-15T05:58:55.059234Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module): \n",
    "    def __init__(self):                                               \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 3,out_channels = 16,kernel_size = 3,stride=1,padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2, return_indices=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=16,kernel_size=2,stride=1,padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=2,stride=1,padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=1,stride=1, return_indices=True)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 32,out_channels = 32,kernel_size = 7,stride=1,padding=0)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2, return_indices=True)\n",
    "        self.fc1 =  nn.Linear(32*7*8, 32*7*8)\n",
    "        self.fc2 =  nn.Linear(32*7*8, 32*7*8)\n",
    "        self.maxunpool1 = nn.MaxUnpool2d(kernel_size=2,stride=2)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=32,out_channels=32,kernel_size = 7,stride=1,padding=0)\n",
    "        self.maxunpool2 = nn.MaxUnpool2d(kernel_size=1,stride=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=2,stride=1,padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=16,out_channels=16,kernel_size=2,stride=1,padding=0)\n",
    "        self.maxunpool3 = nn.MaxUnpool2d(kernel_size=2,stride=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels = 16,out_channels = 3,kernel_size = 3,stride=1,padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x,ind1 = self.maxpool1(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x, ind2 = self.maxpool2(self.conv3(x))\n",
    "        x, ind3 = self.maxpool3(self.conv4(x))\n",
    "        x = x.reshape(-1,32*7*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.reshape(-1,32,7,8)\n",
    "        x = self.maxunpool1(x,indices=ind3)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.maxunpool2(x,indices=ind2)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.maxunpool3(x,indices=ind1,output_size = [4,16,40,45])\n",
    "        x = self.deconv4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T04:19:53.647493Z",
     "start_time": "2020-02-17T04:19:53.641270Z"
    },
    "code_folding": [
     13
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['something1', 'something2', 'something12', 'something17', 'something25', 'something29']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "\n",
    "alist=[\n",
    "    \"something1\",\n",
    "    \"something12\",\n",
    "    \"something17\",\n",
    "    \"something2\",\n",
    "    \"something25\",\n",
    "    \"something29\"]\n",
    "\n",
    "alist.sort(key=natural_keys)\n",
    "print(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T05:58:57.454150Z",
     "start_time": "2020-02-15T05:58:57.445150Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class OFSDataset(Dataset):\n",
    "    def __init__(self,transform):\n",
    "        \n",
    "        self.input_img = None\n",
    "        self.label_img = None\n",
    "        self.transform = None\n",
    "        \n",
    "        input_image_path=glob.glob(\"/home/saikrishna/Desktop/sem4/project/dataset/HS_slices(don't_open)/*.png\")\n",
    "        label_image_path=glob.glob(\"/home/saikrishna/Desktop/sem4/project/dataset/CE_slices(don't_open)/*.png\")\n",
    "        \n",
    "        input_image_path.sort(key = natural_keys)\n",
    "        label_image_path.sort(key = natural_keys)\n",
    "        \n",
    "        input_img = []\n",
    "        label_img = []\n",
    "        inp_list = []\n",
    "        lab_list = []\n",
    "        \n",
    "        for i in range(1,1281):\n",
    "            inp_im = cv2.imread(input_image_path[i])\n",
    "            inp_list.append(inp_im)\n",
    "            \n",
    "            lab_im = cv2.imread(label_image_path[i])\n",
    "            lab_list.append(lab_im)\n",
    "            \n",
    "        self.input_img = inp_list\n",
    "        self.label_img = lab_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1280\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert 0<=i<1281, f'i={i} corresponding to item number {i+1} exceeds size of the dataset that is {self.__len__()}'\n",
    "        \n",
    "        input_image = self.input_img[i]\n",
    "        label_image = self.label_img[i]\n",
    "        \n",
    "        \n",
    "#         print(self.transform)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            input_image = self.transform(input_image)\n",
    "            label_image = self.transform(label_image)\n",
    "     \n",
    "    # 45*40*4 = 7200\n",
    "    # 45*40 = 1800\n",
    "    \n",
    "        else:\n",
    "#             print(\"input_image.shape :\",input_image.shape) #(45,40,4)\n",
    "            input_image = input_image.reshape(40*45, 3)\n",
    "            input_image = input_image.transpose(1, 0)\n",
    "            input_image = input_image.reshape(3, 40, 45)            \n",
    "            input_image = input_image/255.\n",
    "            input_image = torch.from_numpy(input_image)\n",
    "            input_image = input_image.to(dtype=torch.float32)\n",
    "            \n",
    "            label_image = label_image.reshape(40*45, 3)\n",
    "            label_image = label_image.transpose(1, 0)\n",
    "            label_image = label_image.reshape(3, 40, 45)            \n",
    "            label_image = label_image/255.\n",
    "            label_image = torch.from_numpy(label_image)\n",
    "            label_image = label_image.to(dtype=torch.float32)\n",
    "            \n",
    "        return input_image,label_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T05:59:05.758559Z",
     "start_time": "2020-02-15T05:59:05.752401Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, loader, loss_criterion, optimizer, num_epochs):\n",
    "    #(4,3,40,45)\n",
    "#     model.train()\n",
    "    for epoch in tqdm(range(num_epochs)): \n",
    "        for images, labels in loader: \n",
    "            if torch.cuda.is_available():\n",
    "                images = images.to(device = 'cuda')\n",
    "                labels = labels.to(device = 'cuda')\n",
    "#             print(\"ok\")\n",
    "#             print(f\"images.shape - {images.shape} | labels.shape - {labels.shape}\")\n",
    "            \n",
    "            outputs = model(images) # do forward propagation\n",
    "            loss = loss_criterion(outputs.squeeze(), labels.to(dtype = torch.float)) # compute loss\n",
    "            optimizer.zero_grad() # make sure gradients of parameters are zeroed before backpropagation to avoid accumulation\n",
    "            loss.backward() # do the backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "        \n",
    "        if epoch%25 == 0:\n",
    "            print(f'Training loss at epoch {epoch+1}:\\t{loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T08:24:18.432939Z",
     "start_time": "2020-02-15T05:59:11.038242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c93cac4812444218a2ee7b23c649800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1:\t0.948051929473877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/saikrishna/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-001a8e2d011a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-001a8e2d011a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     torch.save(\n",
      "\u001b[0;32m<ipython-input-58-fbd95705886b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, loss_criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make sure gradients of parameters are zeroed before backpropagation to avoid accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# do the backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    mymodel = MyModel()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        mymodel = mymodel.to(device='cuda')\n",
    "\n",
    "    loss_criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(mymodel.parameters(), lr=0.008)\n",
    "\n",
    "    train_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dset_train = OFSDataset(transform = None)\n",
    "    train_loader = DataLoader(dset_train, batch_size=100, shuffle=True, num_workers=4)\n",
    "    \n",
    "    train(mymodel, train_loader, loss_criterion, optimizer, 500)\n",
    "    \n",
    "    torch.save(\n",
    "        {'epoch': 500,\n",
    "         'model': mymodel.state_dict(),\n",
    "         'optimizer': optimizer.state_dict(),\n",
    "         'loss': loss_criterion,\n",
    "        }, '500_sgd_008_100.pth')\n",
    "    \n",
    "#     test('new_new_chkpt_500_sgd_008_64.pth', test_loader, loss_criterion)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
